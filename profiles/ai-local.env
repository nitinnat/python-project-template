# AI/ML Local Development - Ollama with embeddings
# Best for: AI apps, RAG systems, local LLM development, privacy-first AI
# Containers: Backend, PostgreSQL (PGVector), Redis, Ollama
# Models: qwen2.5:7b (chat), nomic-embed-text (embeddings)
# Dependencies: Base packages only (no cloud LLM SDKs)
# Note: Add OLLAMA_MODELS=qwen2.5:7b,nomic-embed-text to .env

ENABLE_BACKEND=true
ENABLE_REDIS=true
ENABLE_POSTGRES=true
ENABLE_PGVECTOR=true
ENABLE_MONGODB=false
ENABLE_NEO4J=false
ENABLE_RABBITMQ=false
ENABLE_CELERY_WORKER=false
ENABLE_CELERY_BEAT=false
ENABLE_FRONTEND=false
ENABLE_NGINX=false

ENABLE_LLM_OPENAI=false
ENABLE_LLM_ANTHROPIC=false
ENABLE_LLM_GOOGLE=false
ENABLE_LLM_OLLAMA=true
ENABLE_LLM_LITELLM=false
ENABLE_LLM_LANGCHAIN=false
