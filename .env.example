# App Configuration
APP_NAME=python-project-template
APP_ENV=development
APP_DEBUG=true
SECRET_KEY=change-this-to-a-random-secret-key-in-production

# Backend
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
BACKEND_RELOAD=true

# Frontend
VITE_API_URL=http://localhost:8000/api/v1

# PostgreSQL
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=app_db

# MongoDB
MONGODB_HOST=mongodb
MONGODB_PORT=27017
MONGODB_USER=mongo
MONGODB_PASSWORD=mongo
MONGODB_DB=app_db

# Neo4j
NEO4J_HOST=neo4j
NEO4J_PORT=7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# Redis
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# RabbitMQ
RABBITMQ_HOST=rabbitmq
RABBITMQ_PORT=5672
RABBITMQ_USER=guest
RABBITMQ_PASSWORD=guest

# Celery
CELERY_BROKER_URL=amqp://guest:guest@rabbitmq:5672//
CELERY_RESULT_BACKEND=redis://redis:6379/0

# OpenAI
OPENAI_API_KEY=your-openai-api-key

# Anthropic
ANTHROPIC_API_KEY=your-anthropic-api-key

# Google Gemini (either GOOGLE_API_KEY or GEMINI_API_KEY is accepted)
GOOGLE_API_KEY=your-google-api-key
# GEMINI_API_KEY=your-google-api-key
# GOOGLE_CLIENT_ID=optional-if-using-oauth
# GOOGLE_CLIENT_SECRET=optional-if-using-oauth

# Ollama (local). When using the Ollama Docker container, set to http://ollama:11434
OLLAMA_HOST=http://ollama:11434
# Comma-separated list of Ollama models to auto-pull on startup
OLLAMA_MODELS=phi3,nomic-embed-text

# CORS
CORS_ORIGINS=http://localhost:3000,http://localhost:5173,http://localhost:80

# Feature Flags - Services
# Control which services are started with Docker Compose
ENABLE_BACKEND=true
ENABLE_REDIS=true
ENABLE_POSTGRES=true
ENABLE_PGVECTOR=true
ENABLE_MONGODB=false
ENABLE_NEO4J=false
ENABLE_RABBITMQ=false
ENABLE_CELERY_WORKER=false
ENABLE_CELERY_BEAT=false
ENABLE_FRONTEND=true
ENABLE_NGINX=true

# Feature Flags - LLM Providers
# Control which LLM provider dependencies are installed and available
ENABLE_LLM_OPENAI=false
ENABLE_LLM_ANTHROPIC=false
ENABLE_LLM_GOOGLE=false
ENABLE_LLM_OLLAMA=true
ENABLE_LLM_LITELLM=false
ENABLE_LLM_LANGCHAIN=false
